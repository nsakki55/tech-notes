{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# „Éá„Éº„Çø„Çª„ÉÉ„Éà„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "dataset = load_dataset(\"llm-book/livedoor-news-corpus\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category': 'livedoor-homme',\n",
      "  'content': 'Êó•Â∏∏„ÅÆ‰ΩïÊ∞ó„Å™„ÅÑÊ∞óÊåÅ„Å°„ÇíTwitter„Å´„Å§„Å∂„ÇÑ„ÅÑ„Åü„Çä„ÄÅÂÆüÂêçÁôªÈå≤„ÅÆFacebook„ÅßÊáê„Åã„Åó„ÅÑÂèã‰∫∫„Å®ÂÜç‰ºö„Åó„Åü„Çä„ÄÅSNS„ÅØ„ÇÇ„ÅØ„ÇÑÊàë„ÄÖ„ÅÆÁîüÊ¥ª„Å´„Åä„ÅÑ„Å¶Ê¨†„Åã„Åõ„Å™„ÅÑÂ≠òÂú®„Å®„Å™„Çä„Å§„Å§„ÅÇ„Çã„ÄÇÂÖàÊó•„ÄÅÂõΩÂÜÖ„ÅÆÊúàÈñìÂà©Áî®ËÄÖÊï∞„Åå1,000‰∏á‰∫∫„ÇíÁ™ÅÁ†¥„Åó„ÄÅmixiÔºà1,520‰∏á‰∫∫„ÄÅ2011Âπ¥12ÊúàÁèæÂú®Ôºâ„ÇíËøΩ„ÅÑÊäú„Åè„ÅÆ„ÇÇÊôÇÈñì„ÅÆÂïèÈ°å„Å®ÊÄù„Çè„Çå„ÇãFacebook„Åß„ÅØ„ÄÅË®∫Êñ≠„ÇÑ„Ç≤„Éº„É†„Å™„Å©Êßò„ÄÖ„Å™„Ç¢„Éó„É™„ÅåÁîü„Åæ„Çå„ÄÅ„É¶„Éº„Ç∂„Éº„ÅÆ„Çø„Ç§„É†„É©„Ç§„É≥„Çí‰ªäÊó•„ÇÇË≥ë„Çè„Åó„Å¶„ÅÑ„Çã„ÄÇ„Åó„Åã„Åó„ÄÅ„Åù„ÅÆ‰∏ÄÊñπ„Åß„ÄÅFacebook„ÇíÊÇ™Áî®„Åô„Çã„Ç±„Éº„Çπ„ÇÇ„Åæ„ÅüÂæê„ÄÖ„Å´Â¢ó„ÅàÂßã„ÇÅ„Å¶„ÅÑ„Çã„ÄÇ  '\n",
      "             'Facebook„Åß„ÅØ„ÄÅ2008Âπ¥1Êúà„Å´API„ÅåÂÖ¨Èñã„Åï„Çå„Å¶‰ª•Êù•„ÄÅÊßò„ÄÖ„Å™„Ç¢„Éó„É™„ÅåË™ïÁîü„Åó„Å¶„ÅÑ„Çã„Åå„ÄÅÂêåÂπ¥8Êúà„Å´„ÅØ„Éú„ÉÉ„ÉàÂûã„ÅÆ‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„ÄåKOOBFACE„Äç„ÅåÁ¢∫Ë™ç„Åï„Çå„ÄÅÊÑüÊüì„ÇíÂ∫É„Åí„Åü„ÄÇ„Åù„ÅÆÊâãÂè£„Å®„ÅØ„ÄÅ„Äå„ÅÇ„Å™„Åü„Åå„Éì„Éá„Ç™„Å´Âá∫„Å¶„ÅÑ„Åæ„Åô„ÇàÔºÅ„Äç„Å®„ÅÑ„ÅÜ„É°„ÉÉ„Çª„Éº„Ç∏„ÅåÂ±ä„Åç„ÄÅYouTube„Å´ÂÅΩË£Ö„Åó„ÅüURL„Å´„Ç¢„ÇØ„Çª„Çπ„Åô„Çã„Å®„ÄÅÂãïÁîªÂÜçÁîü„ÅÆ„Åü„ÇÅ„Å´„Éó„É≠„Ç∞„É©„É†„ÅÆ„Ç§„É≥„Çπ„Éà„Éº„É´„ÇíÊ±Ç„ÇÅ„Çâ„Çå„ÄÅ‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„Åï„Åõ„Çã„Å®„ÅÑ„ÅÜ„ÇÇ„ÅÆ„ÄÇ  '\n",
      "             '‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„Å´„ÅØ„ÄÅÁîªÈù¢„Å´ÂÅΩ„ÅÆÊÑüÊüìË≠¶Âëä„ÇíË°®Á§∫„Åó„ÄÅÈßÜÈô§„ÅÆ„Åü„ÇÅ„ÅÆÂÅΩ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇΩ„Éï„Éà„ÇíË≥ºÂÖ•„Åï„Åõ„ÄÅ„ÇØ„É¨„Ç∏„ÉÉ„Éà„Ç´„Éº„ÉâÊÉÖÂ†±„Å™„Å©„ÅÆÂÄã‰∫∫ÊÉÖÂ†±„ÇíÁõó„ÇÄ„ÇÇ„ÅÆ„ÇÑ„ÄÅ„Éñ„É©„Ç¶„Ç∂„Åß„É≠„Ç∞„Ç§„É≥ÊôÇ„ÅÆ„Ç¢„Ç´„Ç¶„É≥„ÉàÊÉÖÂ†±„ÇíÁõó„ÇÄ„ÇÇ„ÅÆ„Å™„Å©„ÅåÂ≠òÂú®„ÄÇÊõ¥„Å´„ÄÅ„Åù„ÅÆ„É¶„Éº„Ç∂„Éº„ÅÆFacebook„Éï„É¨„É≥„ÉâÂÆõ„Å´„ÇÇ‰∏çÊ≠£„Å™„É°„ÉÉ„Çª„Éº„Ç∏„ÇíËá™ÂãïÈÄÅ‰ø°„Åô„Çã„Åì„Å®„Å´„Çà„Å£„Å¶„ÄÅÊÑüÊüìË¶èÊ®°„ÇíÊã°Â§ß„Åó„Å¶„ÅÑ„Åè„ÅÆ„Å†„ÄÇ  '\n",
      "             '2010Âπ¥12Êúà„Å´„ÅØFacebook„ÅÆÂÖ¨Âºè„Ç¢„Ç´„Ç¶„É≥„Éà„ÇíÈ®ô„Çä„ÄÅ‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„Çí„Ç§„É≥„Çπ„Éà„Éº„É´„Åï„Åõ„Çà„ÅÜ„Å®„Åô„Çã„Çπ„Éë„É†„É°„Éº„É´„ÇÑ„ÄÅ2011Âπ¥1Êúà„Å´„ÅØ„Ç¢„Ç´„Ç¶„É≥„Éà„ÅÆÊõ¥Êñ∞„Å´ÂøÖË¶Å„Å®„Åó„Å¶„ÄÅÂÄã‰∫∫ÊÉÖÂ†±„ÇíÁõó„ÇÄ„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞„Çµ„Ç§„Éà„ÇíÁ¢∫Ë™ç„ÄÇ„Åù„ÅÆ‰ªñ„Å´„ÇÇ„ÄÅÂèØÊÑõ„Çâ„Åó„ÅÑÂ•≥ÊÄß„ÅÆ„Éó„É≠„Éï„Ç£„Éº„É´ÁîªÂÉè„ÇíËºâ„Åõ„Åü‰∫∫Áâ©„Åã„ÇâÂ•ΩÊÑèÁöÑ„Å™„É°„ÉÉ„Çª„Éº„Ç∏„ÅåÂ±ä„Åç„ÄÅÊê∫Â∏Ø„Ç¢„Éâ„É¨„Çπ„Å∏„ÅÆÈÄ£Áµ°„ÇíÊ±Ç„ÇÅ„Çã„Çπ„Éë„É†„É°„ÉÉ„Çª„Éº„Ç∏„Å™„Å©„ÄÅ„Åù„ÅÆÊâãÂè£„ÅØÂπ¥„ÄÖÂ§öÊßòÂåñ„Åó„Å¶„ÅÑ„Çã„ÄÇ  '\n",
      "             'Facebook„ÅÆ„Åø„Å™„Çâ„Åö„ÄÅ‰ªäÂπ¥1Êúà„Å´„ÅØTwitterÂÖ¨Âºè„Ç¢„Ç´„Ç¶„É≥„Éà„ÇíÈ®ô„Çã„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ë©êÊ¨∫„Çµ„Ç§„Éà„ÇÇÁ¢∫Ë™ç„Åï„Çå„ÄÅÊò®Âπ¥12Êúà„ÅÆË≠¶ÂØüÂ∫Å„Å´„Çà„ÇãÁô∫Ë°®„Åß„ÅØ„ÄÅSNS‰ª•Â§ñ„Å´„ÇÇ„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ë©êÊ¨∫„ÅßÁ¥Ñ2,000‰∏áÂÜÜ„ÄÅ‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„ÅßÁ¥Ñ2ÂÑÑ8,000‰∏áÂÜÜ„ÇÇ„ÅÆË¢´ÂÆ≥„ÅåÁô∫Áîü„Åó„Å¶„ÅÑ„ÇãÂÆüÊÖã„ÅåÊòé„Çâ„Åã„Å´„ÄÇ„Åù„Åó„Å¶„ÄÅ3Êúà30Êó•„Å´„ÅØ‚Äú„Å™„Çä„Åô„Åæ„Åó‚ÄùÁ≠â„ÅÆ‰∏çÊ≠£„Å™ÊâãÊÆµ„Å´„Çà„ÇãIDÔºè„Éë„Çπ„ÉØ„Éº„Éâ„Å™„Å©„ÅÆÂèñÂæó„ÇíÁ¶ÅÊ≠¢„Åó„ÄÅ„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ë©êÊ¨∫„ÇíÂèñ„ÇäÁ∑†„Åæ„Çã„Åü„ÇÅ„ÅÆ‰∏çÊ≠£„Ç¢„ÇØ„Çª„ÇπÁ¶ÅÊ≠¢Ê≥ï„ÅÆÊîπÊ≠£Ê°à„ÅåÊàêÁ´ã„Åó„Åü„Å∞„Åã„Çä„Å†„ÄÇ  '\n",
      "             '„Éï„Ç£„ÉÉ„Ç∑„É≥„Ç∞Ë©êÊ¨∫„ÅÆ‰ªñ„Å´„ÇÇ„ÄÅ„Ç¢„ÉÄ„É´„Éà„Çµ„Ç§„ÉàÁ≠â„Åß„ÄåÂÖ•Â†¥„Äç„ÇÑ„ÄåÂπ¥ÈΩ¢Á¢∫Ë™ç„Äç„Å™„Å©„Çí„ÇØ„É™„ÉÉ„ÇØ„Åó„Åü„Å†„Åë„Åß‚ÄúÁôªÈå≤‚Äù„Åó„Åü„Å®‰∏ÄÊñπÁöÑ„Å´ÈÄöÁü•„Åó„ÄÅIP„Ç¢„Éâ„É¨„Çπ„Å™„Å©„ÇíË°®Á§∫„Åó„Å¶ÂÄã‰∫∫„ÇíÁâπÂÆö„Åó„Åü„Åã„ÅÆ„Çà„ÅÜ„Å´ËÑÖËø´„ÄÅË≤ªÁî®„ÇíË´ãÊ±Ç„Åô„Çã„ÉØ„É≥„ÇØ„É™„ÉÉ„ÇØË©êÊ¨∫„ÇÇÊÄ•Â¢ó„ÄÇ1Êúà18Êó•„Å´„ÅØ„ÄÅ‰∫¨ÈÉΩÂ∫úË≠¶„Çµ„Ç§„Éê„ÉºÁäØÁΩ™ÂØæÁ≠ñË™≤„Å´„Çà„Çä„ÄÅ„ÉØ„É≥„ÇØ„É™„ÉÉ„ÇØË©êÊ¨∫„Çµ„Ç§„Éà„Å´Èñ¢ÈÄ£„Åô„Çã‰∏çÊ≠£Êåá‰ª§ÈõªÁ£ÅÁöÑË®òÈå≤‰æõÁî®‰∫ã‰ª∂„ÄÅÈÄöÁß∞‚Äú„Ç¶„Ç§„É´„Çπ‰ΩúÊàêÁΩ™‚Äù„ÅÆ‰æõÁî®ÂÆπÁñë„ÅßË¢´ÁñëËÄÖ6‰∫∫„ÅåÈÄÆÊçï„Åï„Çå„Åü„ÄÇ  '\n",
      "             'ÊÄ™„Åó„ÅÑ„É™„É≥„ÇØ„ÅØ„ÇØ„É™„ÉÉ„ÇØ„Åó„Å™„ÅÑ„ÅÆ„ÅåÈâÑÂâá„Å†„Åå„ÄÅ‰∏á„Åå‰∏Ä„ÄÅ„Ç¶„Ç§„É´„Çπ„Å´ÊÑüÊüì„Åó„Å¶„Åó„Åæ„Å£„ÅüÂ†¥Âêà„ÄÅÁ´ãÂ†¥„ÅØË¢´ÂÆ≥ËÄÖ„Åã„ÇâÂä†ÂÆ≥ËÄÖ„Å∏„Å®‰∏ÄÂ§â„ÄÇ„Ç¶„Ç§„É´„Çπ„ÅØ„ÄÅÂèã‰∫∫„ÇÑ‰ºöÁ§æ„Å´„Åæ„ÅßÊÑüÊüì„Åó„Å¶„Åó„Åæ„ÅÜÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„ÄÅ‚ÄúËª¢„Å∞„Å¨ÂÖà‚Äù„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇΩ„Éï„Éà„ÅØ„ÄÅ„ÇÇ„ÅØ„ÇÑ„Ç§„É≥„Çø„Éº„Éç„ÉÉ„Éà„ÇíÂà©Áî®„Åô„Çã‰∏ä„ÅßÊúÄ‰ΩéÈôê„ÅÆ„Éû„Éä„Éº„Å®„ÅÑ„Åà„Çã„Å†„Çç„ÅÜ„ÄÇ  '\n",
      "             'ÂêÑÁ§æ„Åã„ÇâÁô∫Â£≤„Åï„Çå„Å¶„ÅÑ„Çã„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇΩ„Éï„Éà„ÅÆ‰∏≠„Åß„ÇÇ„ÄÅ4Âπ¥ÈÄ£Á∂ö„ÅßË≤©Â£≤Êú¨Êï∞1‰Ωç(‚Äª1)„ÇíË®òÈå≤„Åó„Å¶„ÅÑ„Çã„ÅÆ„Åå„ÄÅ„Éà„É¨„É≥„Éâ„Éû„Ç§„ÇØ„É≠„ÅÆ„Äå„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº„Äç„Å†„ÄÇÊúÄÊñ∞Áâà„Äå„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 '\n",
      "             '„ÇØ„É©„Ç¶„Éâ„Äç„ÅØ„ÄÅÂïÜÂìÅÂêç„Å´„ÇÇ„ÅÇ„Çã„Çà„ÅÜ„Å´„ÄÅ„Éë„ÇΩ„Ç≥„É≥‰ΩøÁî®‰∏≠„Å´‰ΩìÊÑü„Åô„Çã‚ÄúÈáç„Åï‚Äù„ÅÆ‰∏ª„Å™ÂéüÂõ†(‚Äª2)„ÅÆÁ¥Ñ80%„Çí„ÇØ„É©„Ç¶„Éâ„Å´ÁßªË°å„Åó„ÄÅÂúßÂÄíÁöÑ„Å™ËªΩ„Åï„ÇíÂÆüÁèæ„ÄÇÈ©öÁï∞ÁöÑ„Å™„Çπ„Éî„Éº„Éâ„Åß‰ΩúÊàê„Åï„Çå„Çã‰∏çÊ≠£„Éó„É≠„Ç∞„É©„É†„Å´„ÇÇ„ÄÅ„ÇØ„É©„Ç¶„Éâ‰∏ä„ÅßÂ∏∏„Å´Êõ¥Êñ∞„Åï„Çå„ÇãÊúÄÊñ∞„ÅÆËÑÖÂ®ÅÊÉÖÂ†±„Çí„É™„Ç¢„É´„Çø„Ç§„É†„ÅßÂèÇÁÖß„Åó„Å¶„ÄÅ„Åô„Å∞„ÇÑ„ÅèÂØæÂøú„Åô„Çã„Åã„ÇâÂÆâÂøÉ„Å†„ÄÇ  '\n",
      "             'Â∑¶Ôºö„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 „ÇØ„É©„Ç¶„Éâ „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ3Âπ¥ÁâàÔºà‰∏≠„Äú‰∏äÁ¥öËÄÖÂêë„ÅëÔºâ ‰∏≠Ôºö„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 „ÇØ„É©„Ç¶„Éâ '\n",
      "             '+‰øùÈô∫ÔºÜPC„Çµ„Éù„Éº„Éà „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ3Âπ¥ÁâàÔºàÂàùÂøÉËÄÖÂêë„ÅëÔºâ Âè≥Ôºö„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº „É¢„Éê„Ç§„É´ for Android '\n",
      "             '„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ1Âπ¥ÁâàÔºàAndroidÁ´ØÊú´Âêë„ÅëÔºâ  '\n",
      "             'Êñ∞Ê©üËÉΩ„Å®„Åó„Å¶„ÄÅFacebook„ÄÅTwitter„ÄÅmixiÂà©Áî®ÊôÇ„Å´Web„Çµ„Ç§„Éà„ÇíË©ï‰æ°„Åó„ÄÅURL„ÅÆÂÆâÂÖ®ÊÄß„ÇíËâ≤Âà•„Å´Ë°®Á§∫„Åó„Å¶„Åè„Çå„Çã„ÅÆ„Åß„ÄÅÂç±Èô∫„Å™„Çµ„Ç§„Éà„Åã„Çâ„É¶„Éº„Ç∂„Éº„ÇíÂÆà„Å£„Å¶„Åè„Çå„Çã„ÄÇ„Éë„ÇΩ„Ç≥„É≥ÂàùÂøÉËÄÖ„ÅÆÊñπ„Å´„ÅØ„ÄÅ1Êó•„ÅÇ„Åü„Çä„Çè„Åö„ÅãÁ¥Ñ3.8ÂÜÜ(‚Äª3)„Çí„Éó„É©„Çπ„Åô„Çã„Å†„Åë„Åß„ÄÅ„ÇØ„É¨„Ç∏„ÉÉ„Éà„Ç´„Éº„Éâ‰∏çÊ≠£‰ΩøÁî®„ÅÆ‰øùÈô∫„Å®„ÄÅ365Êó•Ê∑±Â§ú24ÊôÇ„Åæ„ÅßÂØæÂøú„ÅÆPC„Çµ„Éù„Éº„Éà„Åå‰ªò„ÅÑ„Å¶„Åè„Çã„ÄÇ„Åæ„Åü„ÄÅ„ÉØ„É≥„ÇØ„É™„ÉÉ„ÇØË©êÊ¨∫„Å™„Å©„Å´„Çà„Çã‰∏çÊ≠£Ë´ãÊ±ÇÁîªÈù¢„Åå‰ΩïÂ∫¶„ÇÇË°®Á§∫„Åï„Çå„Å¶„ÅäÂõ∞„Çä„ÅÆÊñπ„Å´„ÅØ„ÄÅ„Éë„ÇΩ„Ç≥„É≥1Âè∞„Å´„Å§„Åç7,980ÂÜÜÔºàÁ®éËæºÔºâ„Åß‰∏çÊ≠£Ë´ãÊ±ÇÁîªÈù¢„ÇíÂâäÈô§„Åô„Çã„ÇØ„É™„Éº„É≥„Éä„ÉÉ„Éó„ÉÑ„Éº„É´„ÇíÊèê‰æõ„Åó„Å¶„Åè„Çå„Çã„ÅÆ„Åß„ÄÅË¢´ÂÆ≥„ÇíÊú™ÁÑ∂„Å´Èò≤„Åê„Å†„Åë„Åß„Å™„Åè„ÄÅË¢´ÂÆ≥„Å´ÈÅ≠„Å£„Å¶„Åó„Åæ„Å£„Åü‰∫∫„Å´„ÇÇÂøÉÂº∑„ÅÑÂë≥Êñπ„Å´„Å™„Å£„Å¶„Åè„Çå„Çã„ÄÇ  '\n",
      "             '„Åæ„Åö„ÅØ„ÄÅ30Êó•ÁÑ°Êñô‰ΩìÈ®ìÁâà„Çí‰ªä„Åô„Åê„Ç§„É≥„Çπ„Éà„Éº„É´„Åó„Å¶„ÄÅ„Åù„ÅÆ‚ÄúËªΩÂø´„Åï‚Äù„Å®‚ÄúÂÆâÂøÉ‚Äù„Çí‰ΩìÈ®ì„Åó„Å¶Ê¨≤„Åó„ÅÑ„ÄÇ4Êúà30Êó•„Åæ„Åß„ÄÅ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ3Âπ¥Áâà„Éª„Éë„ÉÉ„Ç±„Éº„Ç∏Áâà3Âπ¥Áâà„ÇíË≥ºÂÖ•„Åô„Çã„Å®2„ÉµÊúàÁÑ°ÊñôÂª∂Èï∑„Åï„Çå„Çã„Ç≠„É£„É≥„Éö„Éº„É≥„ÇÇÂÆüÊñΩ‰∏≠„Å™„ÅÆ„Åß„ÄÅË≥ºÂÖ•„ÅØ„ÅäÊó©„ÇÅ„Å´„ÄÇ  '\n",
      "             '„Éªlivedoor HOMME„Äå„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 „ÇØ„É©„Ç¶„Éâ„ÄçÁâπÈõÜ„Éö„Éº„Ç∏  „Éª„Åä„Åæ„Åã„ÅõÔºÅ‰∏çÊ≠£Ë´ãÊ±Ç„ÇØ„É™„Éº„É≥„Éä„ÉÉ„Éó„Çµ„Éº„Éì„Çπ '\n",
      "             '„Éª„Äå„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 „ÇØ„É©„Ç¶„Éâ„Äç30Êó•ÁÑ°Êñô‰ΩìÈ®ìÁâà  '\n",
      "             '‚Äª1ÔºöÂÖ®ÂõΩ‰∏ªË¶ÅÂÆ∂ÈõªÈáèË≤©Â∫óÁ≠â„ÅÆPOSÂÆüÂ£≤Áµ±Ë®à„ÅßÂπ¥ÈñìÔºà1Êúà„Äú12ÊúàÔºâË≤©Â£≤Êú¨Êï∞Á¨¨1‰Ωç„ÅÆ„Éô„É≥„ÉÄ„Éº„ÇíË°®ÂΩ∞„Åô„ÇãBCN '\n",
      "             'AWARD„ÅÆ„Çª„Ç≠„É•„É™„ÉÜ„Ç£„ÇΩ„Éï„Éà„Ç¶„Çß„Ç¢ÈÉ®ÈñÄ„Å´„Åä„ÅÑ„Å¶„ÄÅ„Éà„É¨„É≥„Éâ„Éû„Ç§„ÇØ„É≠„Åå2008„Äú2011Âπ¥„ÅÆ4Âπ¥ÈÄ£Á∂ö„ÅßÊúÄÂÑ™ÁßÄË≥û„ÇíÂèóË≥û '\n",
      "             '‚Äª2Ôºö„Ç¶„Ç§„É´„ÇπÂØæÁ≠ñÊ©üËÉΩ„ÅÆÈáç„Åï„ÅÆÂéüÂõ†Ôºù„Ç∑„Ç∞„Éç„ÉÅ„É£„ÅÆ„Åì„Å® ‚Äª3Ôºö„Éà„É¨„É≥„Éâ„Éû„Ç§„ÇØ„É≠„Éª„Ç™„É≥„É©„Ç§„É≥„Ç∑„Éß„ÉÉ„Éó„ÅÆ„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 '\n",
      "             '„ÇØ„É©„Ç¶„ÉâÔºã‰øùÈô∫ÔºÜPC„Çµ„Éù„Éº„Éà „ÉÄ„Ç¶„É≥„É≠„Éº„Éâ3Âπ¥Áâà„ÅÆÈáëÈ°ç„Å®„Ç¶„Ç§„É´„Çπ„Éê„Çπ„Çø„Éº2012 „ÇØ„É©„Ç¶„Éâ '\n",
      "             '„Çπ„Çø„É≥„ÉÄ„Éº„Éâ3Âπ¥Áâà„ÅÆÈÄöÂ∏∏‰æ°Ê†º„ÇíÊó•Ââ≤ÊèõÁÆó„Åó„ÅüÂ†¥Âêà',\n",
      "  'date': '2012-04-18T09:45:00+0900',\n",
      "  'title': 'ÊÄ•ÊàêÈï∑„ÇíÈÅÇ„Åí„ÇãFacebook„Å´Âøç„Å≥ÂØÑ„ÇãÂΩ±',\n",
      "  'url': 'http://news.livedoor.com/article/detail/6475684/'},\n",
      " {'category': 'it-life-hack',\n",
      "  'content': 'Linux„ÅÆ‰∫∫Ê∞ó„Éá„Ç£„Çπ„Éà„É™„Éì„É•„Éº„Ç∑„Éß„É≥„Åß„ÅÇ„ÇãUbuntuÔºà„Ç¶„Éñ„É≥„Éà„Ç•Ôºâ„ÅØ„ÄÅ‰Ωø„Åà„Å∞‰Ωø„ÅÜ„Åª„Å©„ÄÅ‰æøÂà©„Åï„ÇíÂÆüÊÑü„Åô„Çã„ÇÇ„ÅÆ„Å†„ÄÇ‰ªäÂõû„ÅØ„ÄÅUbuntu„ÇíËµ∑Âãï„Åô„ÇãUSB„É°„É¢„É™„Éº„ÅÆ‰ΩúÊàêÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶Ëß£Ë™¨„Åó„Çà„ÅÜ„ÄÇ„Åì„Çå„ÇíÊåÅ„Å°Ê≠©„ÅÑ„Å¶„ÅÑ„Çå„Å∞„ÄÅ„ÅÑ„Å§„Åß„ÇÇUSBËµ∑Âãï„Åå„Åß„Åç„ÇãPC„Åã„ÇâËá™ÂàÜ„ÅÆ„Ç™„É™„Ç∏„Éä„É´Áí∞Â¢É„ÅßUbuntu„ÅåËµ∑Âãï„Åß„Åç„Çã„ÄÇWindows/Mac„É¶„Éº„Ç∂„ÉºÂïè„Çè„Åö„ÄÅÁü•„Å£„Å¶„Åä„ÅÑ„Å¶Êêç„ÅØ„Å™„ÅÑ„Å†„Çç„ÅÜ„ÄÇ   '\n",
      "             '‚ñ†CD„Åã„Çâ„ÅÆËµ∑Âãï„Åß„ÅØ„Éá„Éº„Çø‰øùÂ≠ò„Å´Èõ£ÁÇπ ÂâçÂõû„ÄÅUbuntu„ÅØ„Å©„Åì„Åå‰æøÂà©„Å™„ÅÆ„Åã '\n",
      "             'Windows„Éà„É©„Éñ„É´ÊôÇ„Å´„Éá„Éº„Çø„ÇíÊïëÂá∫„Åß„ÄÅCD/DVD„É°„Éá„Ç£„Ç¢„Åã„ÇâËµ∑Âãï„Åô„Çã„Åì„Å®„Åß„ÄÅWindows„Éë„Éº„ÉÜ„Ç£„Ç∑„Éß„É≥„ÅÆ„Éá„Éº„Çø„ÇíÊïëÂá∫„Åô„ÇãÊñπÊ≥ï„Å´„Å§„ÅÑ„Å¶Ëø∞„Åπ„Åü„ÄÇ  '\n",
      "             'Ubuntu„ÅØ„ÄÅCD/DVD„Åã„ÇâËµ∑Âãï„Åó„ÅüÁä∂ÊÖã„Åß„ÇÇÁõ∏ÂΩì„ÅÆ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωø„ÅÜ„Åì„Å®„Åå„Åß„Åç„ÇãÔºà„Åì„Çå„Å´„Å§„ÅÑ„Å¶„ÅØÂà•„ÅÆÊ©ü‰ºö„Å´Ë≠≤„Çä„Åü„ÅÑÔºâ„ÄÇ„Å†„Åå„ÄÅËµ∑Âãï„ÅåÈÅÖ„ÅÑ„Åì„Å®„Å®„ÄÅËµ∑ÂãïÁî®„É°„Éá„Ç£„Ç¢„Å´„ÅØ„Éá„Éº„Çø„ÇíÊõ∏„ÅçËæº„ÇÅ„Å™„ÅÑ„Åü„ÇÅ„ÄÅ„Éá„Éº„Çø„ÅÆ‰øùÂ≠ò„Å´„ÅØÂà•ÈÄî„ÄÅUSB„É°„É¢„É™„Å™„Å©„ÇíÂà©Áî®„Åó„Å™„Åë„Çå„Å∞„Å™„Çâ„Å™„ÅÑ„Åì„Å®„ÅåÈõ£ÁÇπ„Å†„ÄÇ  '\n",
      "             '‚ñ†Ubuntu„ÅåËµ∑ÂãïÂèØËÉΩ„Å™USB„É°„É¢„É™„Éº„Çí‰ΩúÊàê„Åô„Çã '\n",
      "             'ÂÆü„ÅØ„ÄÅUbuntu„Å´„ÅØËµ∑ÂãïÁî®„ÅÆUSB„É°„É¢„É™„Éº„Çí‰ΩúÊàê„Åô„ÇãÊ©üËÉΩ„Åå„ÅÇ„Çã„ÄÇËµ∑ÂãïÁî®„ÅÆUSB„É°„É¢„É™„Éº„Çí‰ΩúÊàê„Åô„Çã„Å´„ÅØ„ÄÅ„Äå„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„Éª„Éá„Ç£„Çπ„ÇØ„ÅÆ‰ΩúÊàê„Äç„Å®„ÅÑ„ÅÜ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Çí‰Ωø„ÅÜ„ÄÇ„Åì„ÅÆ„Ç¢„Éó„É™„Çí‰Ωø„ÅÜ„Å´„ÅØ„ÄÅUbuntu„ÅÆ„Éá„Çπ„ÇØ„Éà„ÉÉ„Éó„ÅßÂ∑¶ÂÅ¥„Å´‰∏¶„Çì„Å†„É©„É≥„ÉÅ„É£„Éº„ÅÆ„ÅÑ„Å°„Å∞„Çì‰∏ä„Å´„ÅÇ„ÇãÔºªDash„Éõ„Éº„É†ÔºΩ„Çí„ÇØ„É™„ÉÉ„ÇØ„Åô„Çã„ÄÇ  '\n",
      "             '„Äå„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„Éª„Éá„Ç£„Çπ„ÇØ„ÅÆ‰ΩúÊàê„Äç„ÅØ„ÄÅCD/DVD„Åã„ÇâËµ∑Âãï„Åó„ÅüÁä∂ÊÖã„Åß„ÇÇ‰Ωø„Åà„Çã„ÅÆ„Å†„ÄÇ  ‚ñ†‰øùÂ≠òÈ†òÂüü„ÅØFAT32„Å™„Å©„Åß„Éï„Ç©„Éº„Éû„ÉÉ„Éà '\n",
      "             'USB„É°„É¢„É™„Éº„ÅØ16GBÁ®ãÂ∫¶„ÅÇ„Çå„Å∞ÂçÅÂàÜ„ÄÇ„Äå„Çπ„Çø„Éº„Éà„Ç¢„ÉÉ„Éó„Éª„Éá„Ç£„Çπ„ÇØ„ÅÆ‰ΩúÊàê„Äç„Åß„ÄÅËµ∑ÂãïÁî®„ÅÆÈ†òÂüü„Å®„Éá„Éº„Çø‰øùÂ≠òÁî®„ÅÆÈ†òÂüü„ÇíÂàÜ„Åë„Çã„Åì„Å®„Åå„Åß„Åç„Çã„ÅÆ„Åß„ÄÅ„Éá„Éº„Çø‰øùÂ≠òÁî®„Å´4GBÁ®ãÂ∫¶„ÇíÁ¢∫‰øù„Åó„Çà„ÅÜ„ÄÇWindowsÁí∞Â¢É„Åã„Çâ„Åß„ÇÇË™≠„ÅøËæº„ÇÅ„Çã„Çà„ÅÜ„Å´„ÄÅ„Éá„Éº„Çø‰øùÂ≠òÁî®„ÅÆÈ†òÂüü„ÅØFAT32„Å™„Å©„Åß„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Åó„Å¶„Åä„Åè„Åì„Å®„ÄÇ„Åì„Çå„Åß„ÄÅËµ∑ÂãïÁî®„ÅÆUSB„É°„É¢„É™„Éº„Çí‰ΩúÊàê„Åß„Åç„Çã„ÄÇ  '\n",
      "             '„Åì„ÅÆ„É°„É¢„É™„Éº„ÇíÁî®ÊÑè„Åó„Å¶„Åä„Åè„Åì„Å®„Åß„ÄÅ„Ç§„Ç∂„Å®„ÅÑ„ÅÜ„Å®„Åç„Å´„Éá„Éº„Çø„ÇíÊïëÂá∫„Åß„Åç„Çã„ÅÆ„ÅØ„ÇÇ„Å°„Çç„Çì„ÄÅÂ§ñÂá∫ÂÖà„Åß‰ªñ‰∫∫„ÅÆ„Éë„ÇΩ„Ç≥„É≥„ÇíÂÄü„Çä„Å™„Åë„Çå„Å∞„Å™„Çâ„Å™„Åè„Å™„Å£„ÅüÂ†¥Âêà„Åß„ÇÇ„ÄÅUSB„É°„É¢„É™„Éº„Åã„ÇâËµ∑Âãï„Åô„Çã„Åì„Å®„Åß„ÄÅËá™ÂàÜÁî®„ÅÆÁí∞Â¢É„Åß‰Ωø„ÅÑ„ÄÅ„Éá„Éº„Çø„ÇÇÊåÅ„Å°ÈÅã„Å≥„Åß„Åç„Çã„Çè„Åë„Å†„ÄÇ   '\n",
      "             '‚ñ†Ubuntu Japanese Team  Â§ßÂ≥∂ÂÖãÂΩ¶Ôº†katsuoshÔºªdigi2Ôºà„Éá„Ç∏ÈÄöÔºâÔºΩ  '\n",
      "             'digi2„ÅØ„Äå„Éá„Ç∏„Çø„É´ÈÄö„Äç„ÅÆÁï•„Åß„Åô„ÄÇÁèæÂú®„ÅÆ„Éá„Ç∏„Çø„É´Ê©üÂô®„ÅØ‰Ωø„ÅÑ„Åì„Å™„Åó„ÅåÈõ£„Åó„Åè„Å™„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ '\n",
      "             'ÁöÜ„Åï„Çì„Åå„Éá„Ç∏„Çø„É´Ê©üÂô®„ÅÆ„ÄåÈÄö„Äç„Å´Ëøë„Å•„Åè„Åü„ÇÅ„ÅÆÊÉÖÂ†±„Çí„ÄÅÁöÜ„Åï„Çì„Çà„Çä„Åô„Åì„ÅóÈÄö„Å™Âü∑Á≠ÜÈô£„ÅåÊèê‰æõ„Åó„Åæ„Åô„ÄÇ   '\n",
      "             '‚ñ†IT„É©„Ç§„Éï„Éè„ÉÉ„ÇØTwitter  ‚ñ†„Éá„Ç∏ÈÄö„ÅÆË®ò‰∫ã„Çí„ÇÇ„Å£„Å®Ë¶ã„Çã „Éª„ÄåDropbox„Äç„ÅÆUbuntuÁâà„ÇíË©¶„Åô '\n",
      "             'Linux„Åß„ÇÇÂêå„Åò‰Ωø„ÅÑ„Åì„Å™„ÅóÔºÅ „Éª„ÄåUbuntu One„Äç„ÅØLinuxÂØæÂøú Ê•ΩÊõ≤„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂØæÂøú„ÅÆ„ÇØ„É©„Ç¶„Éâ '\n",
      "             '„Éª„Å™„Åú„Åì„Çì„Å™„Å´Èù¢ÂÄí„Å™„ÅÆÔºü\\u3000„Éç„ÉÉ„ÉàÊôÇ‰ª£„ÅÆ„Çµ„Éº„Éì„ÇπËß£Á¥ÑÊâãÁ∂ö„Åç „Éª„Éá„Ç∏„Çø„É´„Ç¨„Ç∏„Çß„ÉÉ„ÉàÊñ∞Ë£ΩÂìÅ„ÅØÔºü\\u3000'\n",
      "             '6Êúà„ÅÆÂ§ßË¶èÊ®°Â±ïÁ§∫‰ºöË§áÊï∞ÈñãÂÇ¨„ÅßÁô∫Ë°®„ÅÇ„Çã„ÅãÔºü „Éª„É°„É¢Âûã„ÇØ„É©„Ç¶„Éâ„Çµ„Éº„Éì„Çπ„ÄåDroplr„Äç ÂÇôÂøòÈå≤„ÇÑ„Éñ„ÉÉ„ÇØ„Éû„Éº„ÇØ„Å´‰Ωø„Åà„Çã',\n",
      "  'date': '2012-06-12T13:00:00+0900',\n",
      "  'title': '„ÅÑ„Å§„Åß„ÇÇ„Å©„Åì„Åß„ÇÇËá™ÂàÜÂ∞ÇÁî®Áí∞Â¢ÉÔºÅ\\u3000UbuntuËµ∑Âãï„Åå„Åß„Åç„ÇãUSB„É°„É¢„É™„Éº„Çí‰ΩúÊàêÔºÅ„Äê„Éá„Ç∏ÈÄö„Äë',\n",
      "  'url': 'http://news.livedoor.com/article/detail/6649789/'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Ë®ìÁ∑¥„Çª„ÉÉ„Éà„ÅÆÊúÄÂàù„ÅÆ‰∫å„Å§„ÅÆ‰∫ã‰æã„ÇíË°®Á§∫„Åô„Çã\n",
    "pprint(list(dataset[\"train\"])[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = \"Êó•Êú¨Ë™ûT5„É¢„Éá„É´„ÅÆÂÖ¨Èñã\"\n",
    "prediction1 = \"T5„É¢„Éá„É´„ÅÆÊó•Êú¨Ë™ûÁâà„ÇíÂÖ¨Èñã\"\n",
    "prediction2 = \"Êó•Êú¨Ë™ûT5„Çí„É™„É™„Éº„Çπ\"\n",
    "prediction3 = \"Japanese T5„ÇíÁô∫Ë°®\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂèÇÁÖßÊñá: Êó•Êú¨Ë™û T 5 „É¢„Éá„É´ „ÅÆ ÂÖ¨Èñã\n",
      "ÁîüÊàêÊñá1: T 5 „É¢„Éá„É´ „ÅÆ Êó•Êú¨Ë™û Áâà „Çí ÂÖ¨Èñã\n",
      "ÁîüÊàêÊñá2: Êó•Êú¨Ë™û T 5 „Çí „É™„É™„Éº„Çπ\n",
      "ÁîüÊàêÊñá3: Japanese T 5 „Çí Áô∫Ë°®\n"
     ]
    }
   ],
   "source": [
    "import ipadic\n",
    "import MeCab\n",
    "\n",
    "# IPAdic„ÇíÁî®„ÅÑ„ÅüMeCab„Çí‰ΩøÁî®„Åó„Å¶„ÄÅÂçòË™ûÂàÜÂâ≤„ÇíË°å„ÅÜ\n",
    "tagger = MeCab.Tagger(f\"-O wakati {ipadic.MECAB_ARGS}\")\n",
    "ref_wakati = tagger.parse(reference).strip()\n",
    "pred_wakati1 = tagger.parse(prediction1).strip()\n",
    "pred_wakati2 = tagger.parse(prediction2).strip()\n",
    "pred_wakati3 = tagger.parse(prediction3).strip()\n",
    "print(f\"ÂèÇÁÖßÊñá: {ref_wakati}\")\n",
    "print(f\"ÁîüÊàêÊñá1: {pred_wakati1}\")\n",
    "print(f\"ÁîüÊàêÊñá2: {pred_wakati2}\")\n",
    "print(f\"ÁîüÊàêÊñá3: {pred_wakati3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "\n",
    "# pandas„ÅÆÂ∞èÊï∞ÁÇπ‰ª•‰∏ã„ÅÆÊ°ÅÊï∞„Çí3„Å´Ë®≠ÂÆö„Åô„Çã\n",
    "pd.options.display.precision = 3\n",
    "\n",
    "def convert_words_to_ids(\n",
    "    predictions: list[str], references: list[str]\n",
    ") -> tuple[list[str], list[str]]:\n",
    "    \"\"\"ÂçòË™ûÂàó„ÇíIDÂàó„Å´Â§âÊèõ\"\"\"\n",
    "    # ÂçòË™û„Å´„É¶„Éã„Éº„ÇØ„Å™ID„ÇíÂâ≤„ÇäÂΩì„Å¶„Çã„Åü„ÇÅ„ÅÆdefaultdict„Çí‰ΩúÊàê„Åô„Çã\n",
    "    word2id = defaultdict(lambda: len(word2id))\n",
    "\n",
    "    # ÂçòË™ûÂå∫Âàá„Çä„ÅÆÊñáÂ≠óÂàó„ÇíIDÊñáÂ≠óÂàó„Å´Â§âÊèõ„Åô„Çã\n",
    "    pred_ids = [\n",
    "        \" \".join([str(word2id[w]) for w in p.split()])\n",
    "        for p in predictions\n",
    "    ]\n",
    "    ref_ids = [\n",
    "        \" \".join([str(word2id[w]) for w in r.split()])\n",
    "        for r in references\n",
    "    ]\n",
    "    return pred_ids, ref_ids\n",
    "\n",
    "def compute_rouge(\n",
    "    predictions: list[str], references: list[str]\n",
    ") -> dict[str, dict[str, float]]:\n",
    "    \"\"\"ROUGE„ÇíÁÆóÂá∫\"\"\"\n",
    "    # ROUGE„Çí„É≠„Éº„Éâ„Åô„Çã\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    # ÂçòË™ûÂàó„ÇíIDÂàó„Å´Â§âÊèõ„Åô„Çã\n",
    "    pred_ids, ref_ids = convert_words_to_ids(predictions, references)\n",
    "    # ÂçòË™ûIDÂàó„ÇíË©ï‰æ°ÂØæË±°„Å´Âä†„Åà„Çã\n",
    "    rouge.add_batch(predictions=pred_ids, references=ref_ids)\n",
    "    # ROUGE„Çπ„Ç≥„Ç¢„ÇíË®àÁÆó„Åô„Çã\n",
    "    scores = rouge.compute(rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
    "    return {k: v.mid for k, v in scores.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/fx7hcx4x7vj7v8gx1yk4k4q80000gn/T/ipykernel_15519/839639873.py:31: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ü§ó Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "# ROUGE„ÇíÁÆóÂá∫„Åó„ÅüÁµêÊûú„ÇíË°®Á§∫„Åô„Çã\n",
    "rouge_results = {\n",
    "    \"ÁîüÊàêÊñá1\": compute_rouge([pred_wakati1], [ref_wakati]),\n",
    "    \"ÁîüÊàêÊñá2\": compute_rouge([pred_wakati2], [ref_wakati]),\n",
    "    \"ÁîüÊàêÊñá3\": compute_rouge([pred_wakati3], [ref_wakati]),\n",
    "}\n",
    "df_list = [\n",
    "    pd.DataFrame.from_dict(rouge_results[k], orient=\"index\")\n",
    "    for k in rouge_results.keys()\n",
    "]\n",
    "display(pd.concat(df_list, keys=rouge_results.keys(), axis=1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(\n",
    "    predictions: list[str], references: list[list[str]]\n",
    ") -> dict[str, int | float | list[float]]:\n",
    "    \"\"\"BLUE„ÇíÁÆóÂá∫\"\"\"\n",
    "    # sacreBLEU„Çí„É≠„Éº„Éâ„Åô„Çã\n",
    "    bleu = load_metric(\"sacrebleu\")\n",
    "    # ÂçòË™ûÂàó„ÇíË©ï‰æ°ÂØæË±°„Å´Âä†„Åà„Çã\n",
    "    bleu.add_batch(predictions=predictions, references=references)\n",
    "    # BLEU„ÇíË®àÁÆó„Åô„Çã\n",
    "    results = bleu.compute()\n",
    "    results[\"precisions\"] = [\n",
    "        round(p, 2) for p in results[\"precisions\"]\n",
    "    ]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bertscore(\n",
    "    predictions: list[str], references: list[str]\n",
    ") -> dict[str, float]:\n",
    "    \"\"\"BERTScore„ÇíÁÆóÂá∫\"\"\"\n",
    "    # BERTScore„Çí„É≠„Éº„Éâ„Åô„Çã\n",
    "    bertscore = load_metric(\"bertscore\")\n",
    "    # ÊñáÂ≠óÂàó„ÇíË©ï‰æ°ÂØæË±°„Å´Âä†„Åà„Çã\n",
    "    bertscore.add_batch(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "    # BERTScore„ÇíË®àÁÆó„Åô„Çã\n",
    "    results = bertscore.compute(lang=\"ja\")\n",
    "    return {\n",
    "        k: sum(v) / len(v)\n",
    "        for k, v in results.items()\n",
    "        if k != \"hashcode\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satsuki/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d972ea284d049cca321cb5f8a92358c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5893 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b234d30ecbf421c979797761ae99a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/736 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Any\n",
    "from transformers import BatchEncoding, PreTrainedTokenizer, AutoTokenizer\n",
    "\n",
    "def preprocess_data(\n",
    "    data: dict[str, Any], tokenizer: PreTrainedTokenizer\n",
    ") -> BatchEncoding:\n",
    "    \"\"\"„Éá„Éº„Çø„ÅÆÂâçÂá¶ÁêÜ\"\"\"\n",
    "    # Ë®ò‰∫ã„ÅÆ„Éà„Éº„ÇØ„Éä„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÇíË°å„ÅÜ\n",
    "    inputs = tokenizer(\n",
    "        data[\"content\"], max_length=512, truncation=True\n",
    "    )\n",
    "    # Ë¶ãÂá∫„Åó„ÅÆ„Éà„Éº„ÇØ„Éä„Ç§„Çº„Éº„Ç∑„Éß„É≥„ÇíË°å„ÅÜ\n",
    "    # Ë¶ãÂá∫„Åó„ÅØ„Éà„Éº„ÇØ„É≥ID„ÅÆ„Åø‰ΩøÁî®„Åô„Çã\n",
    "    inputs[\"labels\"] = tokenizer(\n",
    "        data[\"title\"], max_length=128, truncation=True\n",
    "    )[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# „Éà„Éº„ÇØ„Éä„Ç§„Ç∂„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "model_name = \"retrieva-jp/t5-base-long\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Ë®ò‰∫ã„ÅÆ„Éà„Éº„ÇØ„É≥Êï∞„ÅÆÂàÜÂ∏É„ÇíÂèØË¶ñÂåñ„Åô„Çã\n",
    "\n",
    "# Ë®ìÁ∑¥„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„Å¶ÂâçÂá¶ÁêÜ„ÇíË°å„ÅÜ\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_data,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "# Ê§úË®º„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„Å¶ÂâçÂá¶ÁêÜ„ÇíË°å„ÅÜ\n",
    "validation_dataset = dataset[\"validation\"].map(\n",
    "    preprocess_data,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdd340e6f1946c99527c46065f3f318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/791 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0486370405074773868fee014dd0f4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSeq2SeqLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/transformers/modeling_utils.py:3579\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3577\u001b[0m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[1;32m   3578\u001b[0m         filename \u001b[38;5;241m=\u001b[39m _add_variant(WEIGHTS_NAME, variant)\n\u001b[0;32m-> 3579\u001b[0m         resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   3585\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3586\u001b[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[1;32m   3587\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs,\n\u001b[1;32m   3588\u001b[0m     )\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1240\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1221\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1238\u001b[0m     )\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1389\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1387\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1399\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1915\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1912\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1913\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1915\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1924\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1925\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:549\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    547\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    551\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/urllib3/response.py:949\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 949\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/urllib3/response.py:873\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    870\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 873\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/github/tech-notes/llm-book/src/.venv/lib/python3.11/site-packages/urllib3/response.py:856\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.rye/py/cpython@3.11.5/lib/python3.11/http/client.py:466\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 466\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.rye/py/cpython@3.11.5/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.rye/py/cpython@3.11.5/lib/python3.11/ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.rye/py/cpython@3.11.5/lib/python3.11/ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "# ‰π±Êï∞„Ç∑„Éº„Éâ„Çí42„Å´Âõ∫ÂÆö„Åô„Çã\n",
    "set_seed(42)\n",
    "\n",
    "# Trainer„Å´Ê∏°„ÅôÂºïÊï∞„ÇíÂàùÊúüÂåñ„Åô„Çã\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"output_t5_summarization\", # ÁµêÊûú„ÅÆ‰øùÂ≠ò„Éï„Ç©„É´„ÉÄ\n",
    "    per_device_train_batch_size=8, # Ë®ìÁ∑¥ÊôÇ„ÅÆ„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫\n",
    "    per_device_eval_batch_size=8, # Ë©ï‰æ°ÊôÇ„ÅÆ„Éê„ÉÉ„ÉÅ„Çµ„Ç§„Ç∫\n",
    "    learning_rate=1e-4, # Â≠¶ÁøíÁéá\n",
    "    lr_scheduler_type=\"linear\", # Â≠¶ÁøíÁéá„Çπ„Ç±„Ç∏„É•„Éº„É©\n",
    "    warmup_ratio=0.1, # Â≠¶ÁøíÁéá„ÅÆ„Ç¶„Ç©„Éº„É†„Ç¢„ÉÉ„Éó\n",
    "    num_train_epochs=5, # Ë®ìÁ∑¥„Ç®„Éù„ÉÉ„ÇØÊï∞\n",
    "    evaluation_strategy=\"epoch\", # Ë©ï‰æ°„Çø„Ç§„Éü„É≥„Ç∞\n",
    "    save_strategy=\"epoch\", # „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆ‰øùÂ≠ò„Çø„Ç§„Éü„É≥„Ç∞\n",
    "    logging_strategy=\"epoch\", # „É≠„ÇÆ„É≥„Ç∞„ÅÆ„Çø„Ç§„Éü„É≥„Ç∞\n",
    "    load_best_model_at_end=True, # Ë®ìÁ∑¥Âæå„Å´Ê§úË®º„Çª„ÉÉ„Éà„ÅßÊúÄËâØ„ÅÆ„É¢„Éá„É´„Çí„É≠„Éº„Éâ\n",
    ")\n",
    "\n",
    "# Trainer„ÇíÂàùÊúüÂåñ„Åô„Çã\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Ë®ìÁ∑¥„Åô„Çã\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import PreTrainedModel\n",
    "\n",
    "def convert_list_dict_to_dict_list(\n",
    "    list_dict: dict[str, list]\n",
    ") -> list[dict[str, list]]:\n",
    "    \"\"\"„Éü„Éã„Éê„ÉÉ„ÉÅ„ÅÆ„Éá„Éº„Çø„Çí‰∫ã‰æãÂçò‰Ωç„ÅÆlist„Å´Â§âÊèõ\"\"\"\n",
    "    dict_list = []\n",
    "    # dict„ÅÆ„Ç≠„Éº„ÅÆlist„Çí‰ΩúÊàê„Åô„Çã\n",
    "    keys = list(list_dict.keys())\n",
    "    for idx in range(len(list_dict[keys[0]])):  # ÂêÑ‰∫ã‰æã„ÅßÂá¶ÁêÜ„Åô„Çã\n",
    "        # dict„ÅÆÂêÑ„Ç≠„Éº„Åã„Çâ„Éá„Éº„Çø„ÇíÂèñ„ÇäÂá∫„Åó„Å¶list„Å´ËøΩÂä†„Åô„Çã\n",
    "        dict_list.append({key: list_dict[key][idx] for key in keys})\n",
    "    return dict_list\n",
    "\n",
    "def run_generation(\n",
    "    dataloader: DataLoader, model: PreTrainedModel\n",
    ") -> list[dict[str, Any]]:\n",
    "    \"\"\"Ë¶ãÂá∫„Åó„ÇíÁîüÊàê\"\"\"\n",
    "    generations = []\n",
    "    for batch in tqdm(dataloader):  # ÂêÑ„Éü„Éã„Éê„ÉÉ„ÉÅ„ÇíÂá¶ÁêÜ„Åô„Çã\n",
    "        batch = {k: v.to(model.device) for k, v in batch.items() if k != \"labels\"}\n",
    "        # Ë¶ãÂá∫„Åó„ÅÆ„Éà„Éº„ÇØ„É≥„ÅÆID„ÇíÁîüÊàê„Åô„Çã\n",
    "        batch[\"generated_title_ids\"] = model.generate(**batch)\n",
    "        batch = {k: v.cpu().tolist() for k, v in batch.items()}\n",
    "        # „Éü„Éã„Éê„ÉÉ„ÉÅ„ÅÆ„Éá„Éº„Çø„Çí‰∫ã‰æãÂçò‰Ωç„ÅÆlist„Å´Â§âÊèõ„Åô„Çã\n",
    "        generations += convert_list_dict_to_dict_list(batch)\n",
    "    return generations\n",
    "\n",
    "# „ÉÜ„Çπ„Éà„Çª„ÉÉ„Éà„Å´ÂØæ„Åó„Å¶ÂâçÂá¶ÁêÜ„ÇíË°å„ÅÜ\n",
    "test_dataset = dataset[\"test\"].map(\n",
    "    preprocess_data,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    ")\n",
    "test_dataset = test_dataset.remove_columns([\"labels\"])\n",
    "# „Éü„Éã„Éê„ÉÉ„ÉÅ„ÅÆ‰ΩúÊàê„Å´DataLoader„ÇíÁî®„ÅÑ„Çã\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "# Ë¶ãÂá∫„Åó„ÇíÁîüÊàê„Åô„Çã\n",
    "generations = run_generation(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_title(\n",
    "    generations: list[dict[str, Any]],\n",
    "    dataset: list[dict[str, Any]],\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "):\n",
    "    \"\"\"Ë¶ãÂá∫„Åó„ÅÆÂæåÂá¶ÁêÜ\"\"\"\n",
    "    results = []\n",
    "    # ÂêÑ‰∫ã‰æã„ÇíÂá¶ÁêÜ„Åô„Çã\n",
    "    for generation, data in zip(generations, dataset):\n",
    "        # ID„ÅÆlist„Çí„ÉÜ„Ç≠„Çπ„Éà„Å´Â§âÊèõ„Åô„Çã\n",
    "        data[\"generated_title\"] = tokenizer.decode(\n",
    "            generation[\"generated_title_ids\"],\n",
    "            skip_special_tokens=True,\n",
    "        )\n",
    "        results.append(data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
